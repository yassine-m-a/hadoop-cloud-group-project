# Hadoop Cloud Group Project - TÃ©lÃ©com Paris

<p align="center">
  <img src="./elephant-hadoop.jpg" alt="WAIT WHAT? YOU DON'T KNOW HADOOP?" width="500"/>
</p>

Bienvenue dans notre projet Hadoop distribuÃ© ðŸ˜Ž !

## Participants
Yassine MERNISSI ARIFI <br/>
Julien LAFRANCE <br/>
Omar FEKIH-HASSEN <br/>
Alexandre DONNAT <br/>

## Structure du projet

```bash
HADOOP-CLOUD-GROUP-PROJECT/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ hadoop/              # Configs XML pour HDFS, YARN, MapReduce
â”‚   â”œâ”€â”€ hbase/               # Configs pour HBase 
â”‚   â”œâ”€â”€ spark/               # Configs pour Spark
â”‚   â””â”€â”€ zookeeper/           # zoo.cfg (ZK quorum)
â”‚
â”œâ”€â”€ scripts/                 # Scripts Python pour MapReduce & PySpark
â”‚   â”œâ”€â”€ yarn                 # Mapper et reducer Ã  la main
â”‚   â””â”€â”€ spark                # Scripts Spark
â”‚
â”œâ”€â”€ systemd/                 # Fichiers .service pour dÃ©marrage auto
â”‚   â”œâ”€â”€ hadoop.service       # DÃ©ployÃ© sur le Master Node (22)
â”‚   â”œâ”€â”€ hbase-master.service # DÃ©ployÃ© sur le HManager (22) active, et le HManager standby (9)
â”‚   â”œâ”€â”€ hbase-regionserver.service # DÃ©ployÃ© sur les HRegionServer
â”‚   â””â”€â”€ zookeeper.service    # DÃ©ployÃ© sur toutes les machines
â”‚
â””â”€â”€ README.md              # Ce fichier
```

## Exemples dâ€™exÃ©cution

### Upload dâ€™un fichier dans HDFS (via WebHDFS)
```bash
curl -i -X PUT -T /data2/Public/your_file.xml "http://tp-hadoop-22:9870/webhdfs/v1/user/ubuntu/your_file.xml?op=CREATE&overwrite=true&user.name=ubuntu" -L
```

### Exemple MapReduce sur plusieurs noeuds: calcul de Ï€
```bash
hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar pi 16 1000
```

### Exemple Hadoop Streaming : WordCount (mapper/reducer Ã  la main en Python)
```bash
hadoop jar /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-*.jar \
  -input /user/ubuntu/wikipedia_fr_dump_17Go.xml \
  -output /user/ubuntu/output-mapper-reducer-wc \
  -mapper ~/scripts/mapper.py \
  -reducer ~/scripts/reducer.py \
  -file ~/scripts/mapper.py \
  -file ~/scripts/reducer.py
```

### Exemple PySpark : Job Ã  travers YARN
```bash
/opt/spark/bin/spark-submit \
  --master yarn \
  --deploy-mode client \
  --num-executors 8 \
  --executor-cores 2 \
  --executor-memory 3g \
  --driver-memory 2g \
  --conf spark.sql.shuffle.partitions=16 \
  --conf spark.default.parallelism=16 \
  /home/ubuntu/scripts/pyspark_count_word.py
```
